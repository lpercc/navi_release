client:
  ros__parameters:
    port: 8888

camera:
  ros__parameters:
    type: "fisheye" #fisheye #realsense
    view: "all" # all front
    resize_w: 224 # 224 410
    resize_h: 224 # 224 390
    # view: "front" # all front
    # resize_w: 410 # 224 410
    # resize_h: 390 # 224 390
    cam_f_id: "/dev/left_front_surround"
    cam_r_id: "/dev/right_front_surround"
    cam_l_id: "/dev/right_rear_surround"
    cam_b_id: "/dev/left_rear_surround"

### ekf config file ###
ekf_filter_node:
    ros__parameters:
# The frequency, in Hz, at which the filter will output a position estimate. Note that the filter will not begin
# computation until it receives at least one message from one of theinputs. It will then run continuously at the
# frequency specified here, regardless of whether it receives more measurements. Defaults to 30 if unspecified.
        frequency: 30.0

# ekf_localization_node and ukf_localization_node both use a 3D omnidirectional motion model. If this parameter is
# set to true, no 3D information will be used in your state estimate. Use this if you are operating in a planar
# environment and want to ignore the effect of small variations in the ground plane that might otherwise be detected
# by, for example, an IMU. Defaults to false if unspecified.
        two_d_mode: false

# Whether to publish the acceleration state. Defaults to false if unspecified.
        publish_acceleration: true

# Whether to broadcast the transformation over the /tf topic. Defaultsto true if unspecified.
        publish_tf: true

# 1. Set the map_frame, odom_frame, and base_link frames to the appropriate frame names for your system.
#     1a. If your system does not have a map_frame, just remove it, and make sure "world_frame" is set to the value of odom_frame.
# 2. If you are fusing continuous position data such as wheel encoder odometry, visual odometry, or IMU data, set "world_frame"
#    to your odom_frame value. This is the default behavior for robot_localization's state estimation nodes.
# 3. If you are fusing global absolute position data that is subject to discrete jumps (e.g., GPS or position updates from landmark
#    observations) then:
#     3a. Set your "world_frame" to your map_frame value
#     3b. MAKE SURE something else is generating the odom->base_link transform. Note that this can even be another state estimation node
#         from robot_localization! However, that instance should *not* fuse the global data.
        map_frame: map              # Defaults to "map" if unspecified
        odom_frame: odom            # Defaults to "odom" if unspecified
        base_link_frame: base       # Defaults to "base_link" ifunspecified
        world_frame: odom           # Defaults to the value ofodom_frame if unspecified

        odom0: /utlidar/robot_odom
        odom0_config: [true,  true,  true,
                       true,  true,  true,
                       false, false, false,
                       false, false, false,
                       false, false, false]

        imu0: /utlidar/imu
        imu0_config: [false, false, false,
                      false, false, false,
                      true,  true,  true,
                      false, false, false,
                      false, false, false]

pointcloud_to_laserscan:
  ros__parameters:
    target_frame: base        # 输出 LaserScan 的参考坐标系
    transform_tolerance: 0.01
    min_height: -0.2               # 只保留这个高度范围内的点
    max_height: 0.2
    angle_min: -3.14
    angle_max: 3.14
    angle_increment: 0.0087
    scan_time: 0.1
    range_min: 0.0
    range_max: 5.0

scan_filter:
  ros__parameters:
    filter1:
      name: replace_inf
      type: laser_filters/LaserScanRangeFilter
      params:
        lower_threshold: 0.0
        upper_threshold: 5.0           # 设置为你激光雷达的 range_max
        lower_replacement_value: 0.0    # 可设为 0 或 range_max
        upper_replacement_value: 5.0   # 关键：替代 inf 用 range_max
